---
title: "Projekt ML"
subtitle: "Przewidywanie czasu dostawy jedzenia"
author: "Oliwia Grądzka"
format:
  html:
    self-contained: true
    embed-resources: true
    toc: true
    toc-depth: 4
    toc-location: right
    toc-title: "Spis Treści"
    number-sections: true
    number-depth: 4
    code-fold: show
    code-summary: "show the code"
    code-tools: true
    code-block-bg: true
    code-block-border-left: "black"
    code-line-numbers: false
    code-copy: true
    html-math-method: katex
    smooth-scroll: true
    anchor-sections: true
    link-external-icon: true
    link-external-newwindow: true
    theme: 
      light: cosmo
      dark: darkly
    fontsize: 1.1em
    linestretch: 1.5
df-print: paged
execute: 
  warning: false
  echo: true
  eval: false
editor_options:
  chunk_output_type: console
---

## Wstęp

Celem projektu jest zbudowanie modeli przewidujących czas dostawy jedzenia na podstawie różnych czynników operacyjnych i środowiskowych. Szacowanie czasu realizacji zamówień jest kluczowe przy optymalizacji pracy wielu restauracji.

Dane pochodzą z platformy *Kaggle* i zawierają następujące zmienne:

-   `Order_ID` - unikalny identyfikator zamówienia,

-   `Distance_km` - dystans dostawy w km,

-   `Weather` - warunki pogodowe w trakcie dostawy,

-   `Traffic_level` - poziom natężenia ruchu drogowego,

-   `Time_of_Day` - pora dnia w trakcie dostawy,

-   `Vehicle_Type` - rodzaj pojazdu dostawcy,

-   `Preparation_Time_min` - czas przygotowania zamówienia w minutach,

-   `Courier_Experience_yrs` - doświadczenie kuriera w latach,

-   `Delivery_Time_min` - całkowity czas dostawy w minutach.

## Pakiety

```{r}
#| eval: true

library(tidyverse)
library(tidymodels)
library(moments) #do sprawdzenia skośności i kurtozy
library(ggplot2)
library(scales)
library(glmnet)
library(xgboost)
library(gt)
library(vip)
tidymodels_prefer()
```

## Eksploracja danych 
### Wczytanie danych 

```{r}
#| echo: false
#| eval: true

dane <- read_csv("Food_Delivery_Times.csv")
glimpse(dane)
```

### Braki danych

```{r}
#| echo: false
#| eval: true

tabela_braki <- dane |> 
  summarise(across(everything(), ~ sum(is.na(.)))) |> 
  pivot_longer(everything(), names_to = "zmienna", values_to = "liczba_brakow") |> 
  arrange(desc(liczba_brakow))

tabela_braki
```

  W danych występują braki w zmiennych `Weather`, `Traffic_level`, `Time_of_Day` oraz `Courier_Experience_yrs`. W przypadku zmiennych kategorycznych braki zostaną potraktowane jako najczęściej występująca kategoria, a w przypadku zmiennej `Courier_Experience_yrs` braki zostaną uzupełnione medianą.
  
### Statystyki opisowe zmiennych numerycznych

```{r}
#| echo: false
#| eval: true

numeric_summary <- dane |> 
  select(where(is.numeric)) |> 
  summarise(across(everything(), list(min = ~min(.x, na.rm = TRUE),
                                      max = ~max(.x, na.rm = TRUE),
                                      q1 = ~quantile(.x, 0.25, na.rm = TRUE),
                                      q3 = ~quantile(.x, 0.75, na.rm = TRUE),
                                      mean = ~mean(.x, na.rm = TRUE),
                                      median = ~median(.x, na.rm = TRUE),
                                      sd = ~sd(.x, na.rm = TRUE),
                                      skewness = ~skewness(.x, na.rm = TRUE),
                                      kurtosis = ~kurtosis(.x, na.rm = TRUE)),
  .names = "{col}_{fn}")) |>
  pivot_longer(everything(),
               names_to = c("zmienna", "statystyka"),
               names_sep = "_(?=[^_]+$)",
               values_to = "wartosc") |>
  pivot_wider(names_from = statystyka, values_from = wartosc)

numeric_summary
```

  * Zmienna `Order_ID` służy tylko do identyfikacji - nie jest potrzebna do modelowania.
 
  * Zmienna `Distance_km` waha się od 0.59km do 20km. Występuje duża zmienność dystansów, która będzie miała istotny wpływ na model. Zmienna ma średnią 10.1km prawie równą medianie - 10.2km, więc jej rozkład jest prawie symetryczny. Kurtoza na poziomie 1.77 < 3 sugeruje, że rozkład jest płaski i zmienna nadaje się do modelowania.
  
  * Zmienna `Preparation_Time_min` ma rozstęp od 5 do 29 minut, a średnia wynosi 17 minut. Rozkład jest prawie symetryczny, jest to stabilna zmienna.
  
  * Zmienna `Courier_Experience_yrs` mieści się w zakresie 0-9 lat z medianą równą 5 lat. Skośność na poziomie 0, więc rozkład prawie symetryczny.
  
  * Zmienna `Delivery_Time_min` ma największy zakres wartości od 8 do 153 minut ze średnią 56,7 min i medianą 55.5 min. Skośność wskazuje na rozkład prawoskośny. Kurtoza wynosi 3.28 > 3, więc rozkład jest spiczasty i są obecne wartości odstające.
  
### Histogramy zmiennych numerycznych

```{r}
#| echo: false
#| eval: true

dane |> 
  select(where(is.numeric)) |> 
  pivot_longer(cols = everything(), names_to = "zmienna", values_to = "wartosc")  |>
  ggplot(aes(x = wartosc)) +
  geom_histogram(bins = 30, color = "darkblue", fill = "lightblue") +
  facet_wrap(~ zmienna, scales = "free") +
  labs(title = "Histogramy zmiennych numerycznych", x = NULL, y = "Liczba obserwacji")
```

  Histogramy potwierdzają poprzednie wnioski np. prawoskośność oraz wartości odstające w zmiennej `Delivery_Time_min` lub brak dominacji grup początkujących lub doświadczonych w `Courier_Experience_yrs`.
  
### Wykresy ze zmienną docelową

#### Czas dostawy a natężenie ruchu
```{r}
#| echo: false
#| eval: true

dane |> 
  filter(!is.na(Traffic_Level)) |>
  ggplot(aes(x = Traffic_Level, y = Delivery_Time_min, fill = Traffic_Level)) +
  geom_boxplot(show.legend = FALSE, na.rm = T) +
  scale_fill_manual(values = c("blue", "lightblue", "purple1"))+
  labs(title = "Czas dostawy vs. natężenie ruchu", x = "Natężenie ruchu", y = "Czas dostawy [min]")
```

*Wniosek: Natęzenie ruchu wyraźnie wpływa na czas dostawy - im większe korki, tym dłuższy czas.*

#### Czas dostawy a pogoda
```{r}
#| echo: false
#| eval: true

kolory <- c("blue", "lightblue", "purple1")

dane |> 
  filter(!is.na(Weather)) |>
  ggplot(aes(x = Weather, y = Delivery_Time_min, fill = Weather)) +
  geom_boxplot(show.legend = FALSE, na.rm = T) +
  scale_fill_manual(values = rep(kolory, length.out = length(unique(dane$Weather)))) +
  labs(title = "Czas dostawy vs. warunki pogodowe", x = "Pogoda", y = "Czas dostawy [min]") +
  theme(axis.text.x = element_text(angle = 15, hjust = 1))
```

*Wniosek: Trudne warunki pogodowe wydłużają czas dostawy, śnieg najmocniej utrudnia przemieszczanie się.*

#### Czas dostawy a pora dnia
```{r}
#| echo: false
#| eval: true

dane |> 
  filter(!is.na(Time_of_Day)) |>
  ggplot(aes(x = Time_of_Day, y = Delivery_Time_min, fill = Time_of_Day)) +
  geom_boxplot(show.legend = FALSE, na.rm = T) +
  scale_fill_manual(values = rep(kolory, length.out = length(unique(dane$Time_of_Day)))) +
  labs(title = "Czas dostawy vs. pora dnia", x = "Pora dnia", y = "Czas dostawy [min]")
```

*Wniosek: Najdłuższy czas dostawy wieczorami. Różnice między pozostałymi porami dnia zweryfikuję w dalszej części.*

#### Czas dostawy a typ pojazdu
```{r}
#| echo: false
#| eval: true

dane |> 
  filter(!is.na(Vehicle_Type)) |>
  ggplot(aes(x = Vehicle_Type, y = Delivery_Time_min, fill = Vehicle_Type)) +
  geom_boxplot(show.legend = FALSE, na.rm = TRUE) +
  scale_fill_manual(values = c("blue", "lightblue", "purple1"))+
  labs(title = "Czas dostawy vs. typ pojazdu", 
       x = "Pojazd", 
       y = "Czas dostawy [min]")
```

*Wniosek: Mediany są bardzo zbliżone, ale rower ma większy zakres czasów dostawy.*

#### Czas dostawy a doświadczenie kuriera
```{r}
#| echo: false
#| eval: true

dane |> 
  filter(!is.na(Courier_Experience_yrs)) |>
  ggplot(aes(x = as.factor(Courier_Experience_yrs), 
             y = Delivery_Time_min, 
             fill = as.factor(Courier_Experience_yrs))) +
  geom_boxplot(show.legend = FALSE, na.rm = TRUE) +
  scale_fill_manual(values = rep(kolory, length.out = length(unique(dane$Courier_Experience_yrs)))) +
  labs(title = "Czas dostawy vs. doświadczenie kuriera", 
       x = "Doświadczenie [lata]", 
       y = "Czas dostawy [min]") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

*Wniosek: Wraz ze wzrostem doświadczenia nie widać wyraźnego trendu skracania czasu dostawy.*

Dodatkowo w zmiennej `Delivery_Time_min` wystąpiło 6 wartości odstających w zakresie od 122 do 153 min: 

```{r}
#| echo: false
#| eval: true

wartosci_odst <- boxplot.stats(dane$Delivery_Time_min)$out

tibble(
  liczba_wartosci_odstajacych = length(wartosci_odst),
  min_wartosc_odstajaca = min(wartosci_odst),
  max_wartosc_odstajaca = max(wartosci_odst))
```

### Porównanie zmiennych kategorycznych

```{r}
#| echo: false
#| eval: true

tabela_kat <- function(df, zmienna) {
  df |> 
    count({{zmienna}}) |> 
    mutate(
      procent = round(100 * n / sum(n), 1)
    ) |> 
    arrange(desc(n))
}

tabela_kat(dane, Weather)
tabela_kat(dane, Traffic_Level)
tabela_kat(dane, Time_of_Day)
tabela_kat(dane, Vehicle_Type)
```

  W danych dominują dostawy w dobrych warunkach pogodowych przy średnim lub niskim natężeniu ruchu drogowego w ciągu dnia. Typ pojazdu jest zróżnicowany, ale rowery dominują - 50.3%. Rzadkie kategorie mogą być mniej przewidywalne.

## Przygotowanie danych

### Podział na zbiór treningowy i testowy

```{r}
#| eval: true

set.seed(123)

dane <- dane |>
  mutate(across(c(Weather, Traffic_Level, Time_of_Day, Vehicle_Type), as.factor)) |>
  mutate(
    Traffic_Level = fct_relevel(Traffic_Level, c("Low","Medium","High")),
    Time_of_Day = fct_relevel(Time_of_Day,   c("Morning","Afternoon","Evening","Night")),
    Weather = fct_relevel(Weather, c("Clear","Foggy", "Windy", "Rainy","Snowy")))

split <- initial_split(dane, prop = 0.8, strata = Delivery_Time_min)
train <- training(split)
test <- testing(split)

med_dist <- median(train$Distance_km, na.rm = T)
med_prep <- median(train$Preparation_Time_min, na.rm = T)
thr_out <- quantile(train$Delivery_Time_min, 0.99, na.rm = T)

train <- train |> mutate(is_outlier_delivery = as.integer(Delivery_Time_min > thr_out))
test <- test |> mutate(is_outlier_delivery = as.integer(Delivery_Time_min > thr_out))
```

### Przepis bazowy - drzewa + boosting

```{r}
#| eval: true

rec_base <- recipe(Delivery_Time_min ~ ., data = train) |> 
  update_role(Order_ID, new_role = "ID") |> 
  
  step_impute_mode(Weather, Traffic_Level, Time_of_Day) |> 
  step_impute_median(Courier_Experience_yrs) |> 
  step_other(all_nominal_predictors(), threshold = 0.02) |>
  step_log(Distance_km, offset = 1) |> 
  
  step_mutate(
    Courier_Experience_yrs_gr = cut(Courier_Experience_yrs, c(-Inf,2,5,8,Inf),
                                    labels = c("0-2", "3-5", "6-8", "9+")),
    is_peak_evening = as.integer(Time_of_Day == "Evening"),
    is_night = as.integer(Time_of_Day == "Night"),
    is_motorized = as.integer(Vehicle_Type %in% c("Car","Scooter")),
    extreme_weather = as.integer(Weather == "Snowy"),
    prep_per_km = Preparation_Time_min / (Distance_km + 0.5),
    is_long_distance = as.integer(Distance_km >= med_dist),
    is_heavy_prep = as.integer(Preparation_Time_min >= med_prep),
    traffic_intensity = as.integer(Traffic_Level) - 1L,
    weather_intensity = as.integer(Weather) - 1L) |> 
  
  step_interact(terms = ~ Distance_km:traffic_intensity +
                  Distance_km:is_motorized +
                  weather_intensity:is_motorized +
                  extreme_weather:is_motorized +
                  is_peak_evening:traffic_intensity +
                  traffic_intensity:prep_per_km) |> 
  
  step_dummy(all_nominal_predictors(), one_hot = T) |>
  step_lincomb(all_predictors()) |> 
  step_zv(all_predictors()) |> 
  step_normalize(all_numeric_predictors(), -is_outlier_delivery)


prep_base <- prep(rec_base)
train_base <- juice(prep_base)
test_base <- bake(prep_base, new_data = test)

# test
#colSums(is.na(train_base))
#colSums(is.na(test_base))
#dim(train_base)
#dim(test_base)
#head(train_base, 5)
#lm_test <- lm(Delivery_Time_min ~ ., data = train_base)
#summary(lm_test)
summary(rec_base)
train_base |> count(is_outlier_delivery)
test_base |> count(is_outlier_delivery)

```

W zbiorze znalazłam 11 wartości odstających w zmiennej `Delivery_Time_min` - stanowią 0.9% danych treningowych i 2% danych testowych. Jest ich bardzo mało, więc zdecydowałam się je zostawić, a ich wystapienia oznaczone będą dodatkową informacją `is_outlier_delivery`. 

## Modele

### Przepis - modele liniowe

Przygotowałam również przepis do modeli liniowych, w którym zmienna docelowa została zlogarytmowana, aby zredukować wpływ wartości odstających.

```{r}
#| eval: true

train_lm <- train |> mutate(Delivery_Time_min_log = log1p(Delivery_Time_min))
test_lm  <- test  |> mutate(Delivery_Time_min_log = log1p(Delivery_Time_min))

rec_tree <- rec_base

rec_lm <- recipe(Delivery_Time_min_log ~ ., data = train_lm) |>
  update_role(Order_ID, new_role = "ID") |>
  step_rm(Delivery_Time_min) |>
  step_impute_mode(Weather, Traffic_Level, Time_of_Day) |>
  step_impute_median(Courier_Experience_yrs) |>
  step_other(all_nominal_predictors(), threshold = 0.02) |>
  step_log(Distance_km, offset = 1) |>
  step_mutate(
    Courier_Experience_yrs_gr = cut(Courier_Experience_yrs, c(-Inf,2,5,8,Inf),
                                    labels = c("0-2","3-5","6-8","9+")),
    is_peak_evening  = as.integer(Time_of_Day == "Evening"),
    is_night         = as.integer(Time_of_Day == "Night"),
    is_motorized     = as.integer(Vehicle_Type %in% c("Car","Scooter")),
    extreme_weather  = as.integer(Weather == "Snowy"),
    prep_per_km      = Preparation_Time_min / (Distance_km + 0.5),
    is_long_distance = as.integer(Distance_km >= med_dist),
    is_heavy_prep    = as.integer(Preparation_Time_min >= med_prep),
    traffic_intensity = as.integer(Traffic_Level) - 1L,
    weather_intensity = as.integer(Weather) - 1L
  ) |>
  step_interact(terms = ~
    Distance_km:traffic_intensity +
    Distance_km:is_motorized +
    weather_intensity:is_motorized +
    extreme_weather:is_motorized +
    is_peak_evening:traffic_intensity +
    traffic_intensity:prep_per_km
  ) |>
  step_dummy(all_nominal_predictors(), one_hot = T) |>
  step_lincomb(all_predictors()) |>
  step_zv(all_predictors()) |>
  step_normalize(all_numeric_predictors(), -is_outlier_delivery) 

rec_lm_prep <- prep(rec_lm)
summary(rec_lm_prep) |> head(15)
```

### Specyfikacja

W tej części definiuję specyfikacje modeli, które będą trenowane: Regresja liniowa, Elastic Net, Random Forest, XGBoost + później XGBoost z logarytmem.
Stosuję walidację 5-krotną z warstwowaniem po celu. 

```{r}
#| eval: true

# resampling
folds_tree <- vfold_cv(train, v = 5, strata = Delivery_Time_min)
folds_lm <- vfold_cv(train_lm, v = 5, strata = Delivery_Time_min_log)

spec_lm <- linear_reg() |> 
  set_engine("lm")
  
spec_enet <- linear_reg(penalty = tune(), mixture = tune()) |> 
  set_engine("glmnet")
  
spec_rf <- rand_forest(
  mtry = tune(), 
  min_n = tune(),
  trees = 700) |> 
  set_engine("ranger", importance = "impurity") |> 
  set_mode("regression")

spec_xgb <- boost_tree(
  trees = tune(),
  learn_rate = tune(),
  mtry = tune(),
  tree_depth = tune(),
  min_n = tune(),
  loss_reduction = tune(),
  sample_size = tune()) |>
  set_engine("xgboost") |>
  set_mode("regression")
```

### Workflow

```{r}
#| eval: true

wf_lm <- workflow() |> 
  add_model(spec_lm) |> 
  add_recipe(rec_lm)
  
wf_enet <- workflow() |> 
  add_model(spec_enet) |> 
  add_recipe(rec_lm)
  
wf_rf <- workflow() |>
  add_model(spec_rf) |> 
  add_recipe(rec_tree)
  
wf_xgb <- workflow() |>
  add_model(spec_xgb) |> 
  add_recipe(rec_tree)

# params
rec_tree_prep <- prep(rec_tree)
p_train <- juice(rec_tree_prep) |> 
  select(-Delivery_Time_min)

rf_params <- parameters(wf_rf) |> 
  finalize(p_train)

p <- ncol(p_train)
xgb_params <- parameters(wf_xgb) |> 
  finalize(p_train) |> 
  update(
    trees = trees(c(2500,6000)),
    learn_rate = learn_rate(range = c(0.03, 0.20), trans = NULL),
    tree_depth = tree_depth(c(6, 12)),           
    min_n = min_n(c(1, 10)),                
    loss_reduction = loss_reduction(c(0, 2), trans = NULL),
    sample_size = sample_prop(c(0.8, 1)),
    mtry  = mtry(c(max(1, floor(0.4*p)), max(2, floor(0.8*p)))))
```

### Siatki strojenia i metryki

Siatki RF i XGB są generowane losowo na rozsądnych zakresach, a EN na siatce regularnej. Do metryk uwzględniłam RMSE, MAE i R2, wybór najlepszego modelu odbywa się po najmniejszym RMSE, a w drugiej koleności po najmniejszym MAE. 

```{r}
#| eval: true

grid_enet <- grid_regular(
  penalty(range = c(-6, 1)), 
  mixture(range = c(0, 1)),
  levels = 7)


grid_rf <- grid_random(rf_params, size = 20)
grid_xgb <- grid_random(xgb_params, size = 120) 

metrics_cv <- metric_set(rmse, mae, rsq)

head(grid_enet)
head(grid_rf)
head(grid_xgb)
```

```{r}
#| eval: true
#| echo: false

# funkcje pomocnicze
naj_rmse_mae <- function(res, wf = NULL) {
  sb <- show_best(res, metric = "rmse", n = Inf)
  mae <- collect_metrics(res) |>
    filter(.metric == "mae") |>
    select(.config, mae = mean)

  naj <- sb |>
    left_join(mae, by = ".config") |>
    arrange(mean, mae) |>
    slice(1)

  if (is.null(wf)) {
    transmute(naj, rmse = mean, mae)
  } else {
    pnames <- parameters(wf) |> pull(id)
    select(naj, any_of(pnames))
  }
}

topn_rmse_mae <- function(res, n = 5) {
  sb <- show_best(res, metric = "rmse", n = Inf)
  mae <- collect_metrics(res) |>
    filter(.metric == "mae") |>
    select(.config, mae = mean)

  sb |>
    left_join(mae, by = ".config") |>
    arrange(mean, mae) |>
    slice_head(n = n)
}
```

### Strojenie

```{r}
#| eval: true

# xgboost z tym samym przepisem co lm i enet
wf_xgb_log <- workflow() |> 
  add_model(spec_xgb) |> 
  add_recipe(rec_lm)
  
p_train_lm <- juice(prep(rec_lm)) |> select(-Delivery_Time_min_log)
xgb_log_params <- parameters(wf_xgb_log) |> finalize(p_train_lm)
grid_xgb_log <- grid_random(xgb_log_params, size = 120)

res_xgb_log <- tune_grid(
  wf_xgb_log,
  resamples = folds_lm,
  grid = grid_xgb_log,
  metrics = metrics_cv,
  control = control_grid(save_pred = T))


res_lm <- fit_resamples(
  wf_lm,
  resamples = folds_lm,
  metrics = metrics_cv,
  control = control_resamples(save_pred = T))


res_enet <- tune_grid(
  wf_enet,
  resamples = folds_lm,
  grid = grid_enet,
  metrics = metrics_cv,
  control = control_grid(save_pred = T))

res_rf <- tune_grid(
  wf_rf,
  resamples = folds_tree,
  grid = grid_rf,
  metrics = metrics_cv,
  control = control_grid(save_pred = T))

res_xgb <- tune_grid(
  wf_xgb,
  resamples = folds_tree,
  grid = grid_xgb,
  metrics = metrics_cv,
  control = control_grid(save_pred = T))

# top 5 
collect_metrics(res_lm)
topn_rmse_mae(res_enet, 5)
topn_rmse_mae(res_rf, 5)
topn_rmse_mae(res_xgb, 5)
topn_rmse_mae(res_xgb_log, 5)
```

### Najlepszy model 

W tym kroku wybieram najlepsze konfiguracje w ramach kazdego modelu.

```{r}
#| eval: true

best_enet <- naj_rmse_mae(res_enet, wf_enet)
best_rf <- naj_rmse_mae(res_rf, wf_rf)
best_xgb <- naj_rmse_mae(res_xgb, wf_xgb)
best_xgb_log <- naj_rmse_mae(res_xgb_log, wf_xgb_log)

final_enet <- finalize_workflow(wf_enet, best_enet)
final_rf <- finalize_workflow(wf_rf, best_rf)
final_xgb <- finalize_workflow(wf_xgb, best_xgb)
final_xgb_log <- finalize_workflow(wf_xgb_log, best_xgb_log)

fit_lm <- fit(wf_lm, data = train_lm) 
fit_enet <- fit(final_enet, data = train_lm)
fit_rf <- fit(final_rf, data = train)
fit_xgb <- fit(final_xgb, data = train)
fit_xgb_log <- fit(final_xgb_log, data = train_lm)
``` 

### Predykcja na zbiorze testowym

Obliczam metryki w skali minut na zbiorze testowym i sprwdzam, który model jest najlepszy.

```{r}
#| eval: true

f_odwrotna <- function(x) exp(x) - 1

p_lm <- predict(fit_lm, new_data = test_lm) |> 
  mutate(.pred = f_odwrotna(.pred)) |>
  bind_cols(test |> 
    select(Order_ID, Delivery_Time_min))

p_enet <- predict(fit_enet, new_data = test_lm) |>
  mutate(.pred = f_odwrotna(.pred)) |>
  bind_cols(test |> 
    select(Order_ID, Delivery_Time_min))

p_rf <- predict(fit_rf, new_data = test) |>
  bind_cols(test |> 
    select(Order_ID, Delivery_Time_min))
    
p_xgb <- predict(fit_xgb, new_data = test) |>
  bind_cols(test |> 
    select(Order_ID, Delivery_Time_min))
    
p_xgb_log <- predict(fit_xgb_log, new_data = test_lm) |>
  mutate(.pred = f_odwrotna(.pred)) |>
  bind_cols(test |> 
    select(Order_ID, Delivery_Time_min))

metrics_test <- metric_set(rmse, mae, rsq_trad)

met_lm <- p_lm |> 
  rename(truth = Delivery_Time_min) |> 
  metrics_test(truth, .pred) 
  
met_enet <- p_enet |> 
  rename(truth = Delivery_Time_min) |> 
  metrics_test(truth, .pred)

met_rf <- p_rf |> 
  rename(truth = Delivery_Time_min) |> 
  metrics_test(truth, .pred)
  
met_xgb <- p_xgb |> 
  rename(truth = Delivery_Time_min) |> 
  metrics_test(truth, .pred)
  
met_xgb_log <- p_xgb_log |> 
  rename(truth = Delivery_Time_min) |> 
  metrics_test(truth, .pred)
  
wyniki_test <- bind_rows(
  met_lm |> mutate(model = "Linear Regression"),
  met_enet |> mutate(model = "Elastic Net"),
  met_rf |> mutate(model = "Random Forest"),
  met_xgb |> mutate(model = "XGBoost"),
  met_xgb_log |> mutate(model = "XGBoost log"))|> 
  select(model, .metric, .estimate) |>
  pivot_wider(names_from = .metric, values_from = .estimate)

wyniki_test |> arrange(rmse, mae) |> slice(1)
```

## Porównanie modeli

### Ranking metryk i wykresy RMSE/MAE 

```{r}
#| eval: true
#| echo: false

tabela_metryk <- wyniki_test |> 
  mutate(across(c(rmse, mae, rsq_trad), ~round(.x, 3))) |>
  arrange(rmse, mae) |>
  gt() |> 
  tab_header(title = "Porównanie modeli na zbiorze testowym") |> 
  cols_label(
    model = "Model",
    rmse = "RMSE [min]",
    mae = "MAE [min]",
    rsq_trad = "R²")
  
tabela_metryk

wyniki_long <- wyniki_test |> 
  select(model, rmse, mae) |> 
  pivot_longer(cols = c(rmse, mae), names_to = "metric", values_to = "value")

ggplot(wyniki_long, aes(x = reorder(model, value), y = value, fill = metric)) +
  geom_col(position = position_dodge(width = 0.7), width = 0.6) +
  coord_flip() +
  labs(title = "RMSE/MAE na zbiorze testowym", x = NULL, y = "minuty") +
  scale_fill_manual(values = c("rmse" = "lightblue", "mae" = "orchid")) +
  theme(legend.title = element_blank())
```

**Elastic Net** ma najniższe **RMSE = 9.426** i najwyższe **R2 = 0.826**. Regresja liniowa ma minimalnie niższe MAE, ale wyższe RMSE. EN przeważa nad XGBoost z log o ok.3s RMSE, a nad zwykłym XGBoost o ok. 20s. Przy kryterium RMSE wygrywa model EN, ale gdyby priorytetem było MAE, zwykła regresja liniowa może być alternatywą.

Dwa liniowe modele są na czele w obu metrykach, modele drzewiaste mają większe błędy. Poprzez inżynierię cech oraz transformację z log, modele liniowe radzą sobie lepiej i są bardziej opłacalne (i łatwiejsze w interpretacji) w tym przypadku niż modele z boostingiem lub lasem.

### Reszty i błędy

```{r}
#| eval: true
#| echo: false

pred_all <- bind_rows(
  p_lm   |> mutate(model = "Linear Regression"),
  p_enet |> mutate(model = "Elastic Net"),
  p_rf   |> mutate(model = "Random Forest"),
  p_xgb  |> mutate(model = "XGBoost")
) |>
  rename(truth = Delivery_Time_min) |>
  mutate(residual = truth - .pred,
         abs_error = abs(residual))
         
ggplot(pred_all, aes(x = residual, fill = model)) +
  geom_density(alpha = 0.35) +
  labs(title = "Rozkład reszt", x = "błąd [min]", y = "gęstość")
  theme(legend.position = "bottom")
```

Wszystkie rozkłady są wyraźnie skupione wokół zera, ale modele liniowe mają lżejsze ogony, co oznacza mniej dużych błędów. RF i XGB mają więcej niedoszacowań z prawej strony, co oznacza, żę można by rozważyć mocniejsze ograniczenia złożoności tych modeli. Wybór Elastic Net jako model bazowy jest uzasadniony. 

```{r}
#| eval: true
#| echo: false

  ggplot(pred_all, aes(x = .pred, y = truth, colour = model)) +
    geom_point(alpha = 0.25) +
    geom_abline(slope = 1, intercept = 0, linetype = 2) +
    geom_smooth(se = F) +
    labs(title = "Kalibracja predykcji", x = "predykcja [min]", y = "rzeczywiste [min]") +
    theme(legend.position = "bottom")
```

W środkowym zakesie - ok. 35 - 90 min. - wszystkie modele są dobrze skalibrowane. Dla długich dostaw powyżej 100 min modele XGBoost oraz RF mają krzywe powyżej inii x=y, czyli zaniżają przewidywania. Krzywe kalibracyjne dla EN i LR niemal się pokrywają i przebiegają poniżej linii idealnej, co wskazuje na niewielkie stałe zawyżanie predykcji. Ze względu na małą liczbę obserwacji odstających nie jest to problem nieliniowości. W projekcie pozostawię model bez kolejnej kalibracji, aby utrzymać porównywalność RMSE i MAE. 

```{r}
#| eval: true
#| echo: false

gr_metryki <- function(df, gr_var){
  df |> 
    group_by(model, {{gr_var}}) |>
    summarise(
      n = n(),
      RMSE = rmse_vec(truth, .pred),
      MAE = mae_vec(truth, .pred),
      .groups = "drop") |> 
      arrange(model, desc(n))}

blad_weather <- pred_all |> left_join(test |> 
  select(Order_ID, Weather), by = "Order_ID") |> 
    gr_metryki(Weather)
blad_weather
```

**Błędy według pogody**
Modele EN i LR są najlepsze w większości warunków pogodowych - Clear, Rainy, Windy, natomiast RF jest wyraźnie lepszy (RMSE ok. 7.6) niż EN/LR (RMSE ok.12.4/12.6) przy śniegu. Mgła stanowi wyzwanie dla wszystkich modeli przy małym n = 17. Ogólnie wygrywa Elastic Net, ale w warunkach skrajnych modele drzewiaste poradzą sobie lepiej i jest to jedyny minus modeli liniowych. Aby uwzględnić ten problem należałoby rozważyć model hybrydowy lub dodatkowe cechy. 

```{r}
#| eval: true
#| echo: false

blad_traffic <- pred_all |> left_join(test |> 
  select(Order_ID, Traffic_Level), by = "Order_ID") |> 
    gr_metryki(Traffic_Level)
blad_traffic
```

**Błędy według natężenia ruchu**
Najmniejsze błedy występują przy średnim natężeniu ruchu na drodze - EN/LR (RMSE ok. 7.2/7.19), a największe przy wysokim (RMSE ok. 11.6). Modele drzewiaste mają konsekwentnie wyższe błędy w każdej klasie, co oznacza, że modele liniowe dominują niezależnie od natężenia ruchu. 

```{r}
#| eval: true
#| echo: false

blad_time <- pred_all |> left_join(test |>
  select(Order_ID, Time_of_Day), by = "Order_ID") |> 
    gr_metryki(Time_of_Day)
blad_time
```

**Błędy według pory dnia**
Najmniejsze błędy wystepują z rana, największe w nocy. Elastic Net utrzymuje przewagę przez cały dzień i jest najbardziej stabilny. Każdy model ma trudności przy nocy, co może być spowodowane mała ilościa danych i większą losowością. Należy traktować to jako ograniczenie w danych.

```{r}
#| eval: true
#| echo: false
blad_vehicle <- pred_all |> left_join(test |> 
  select(Order_ID, Vehicle_Type), by = "Order_ID") |> 
    gr_metryki(Vehicle_Type)
blad_vehicle
```

**Błędy według typu pojazdu**
Najniższe błędy wykazuje dostawa samochodem, a dostawa rowerem charakteryzuje się najwyższymi błędami. Zmienność czasu przejazdu rowerem podnosi błędy, ponieważ wystepuje duża wrażliwość na warunki atmosferyczne. W tej kategorii również modele liniowe radzą sobie najlepiej w każdej klasie. Użycie cechy `is_motorized` pomogło, a otrzymane wyniki tylko wzmocniły wybór EN jako modelu globalnego. Rf i XGB są widocznie słabsze.

```{r}
# bledy a dystans
test_bins <- test |> 
mutate(distance_bin = cut(Distance_km,
  breaks = quantile(Distance_km, probs = seq(0,1,0.25), na.rm = T),
  include.lowest = TRUE))

blad_distance <- pred_all |> left_join(test_bins |>
  select(Order_ID, distance_bin), by = "Order_ID") |>
  group_by(model, distance_bin) |> 
    summarise(
      n = n(),
      RMSE = rmse_vec(truth, .pred),
      MAE = mae_vec(truth, .pred),
      .groups = "drop") 
  
ggplot(blad_distance, aes(x = distance_bin, y = RMSE, group = model, colour = model)) +
  geom_line() + geom_point() +
  labs(title = "RMSE w zależności od dystansu (kwartyle)", x = "przedział dystansu [km]", y = "RMSE [min]") +
  theme(legend.position = "bottom")
```

RMSE rośnie wraz z dystansem. Najmniejsze błędy występują w zakresie 5.2 - 10.4 km, a przy dystansie >10km widać wielki skok błędów. Przy krótkim i średnim dystansie najlepiej radzi sobie LR/EN. Przy najdłuższych trasach XGB ma najniższy RMSE, więc najlepiej wyłapuje nielibiowość. Przy najkrótszych dostawach róznie między modelami są stosunkowo niewielkie. Dystans dostawy jest kluczowym czynnikiem błędu. Modele liniowe znów dominują przez większość zakresu, jednak przy skrajnych przypadkach XGB zyskuje przewagę. To kolejny przykład potencjału na model hybrydowy z globalnym modelem liniowym z boostingiem dla najdłuższych tras.

### Ważność cech

```{r}
#| eval: true
#| echo: false

vip_rf <- vip(extract_fit_parsnip(fit_rf)$fit, num_features = 12) +
  labs(title = "Ważność cech - Random Forest")
vip_rf

vip_xgb <- vip(extract_fit_parsnip(fit_xgb)$fit, num_features = 15) +
  labs(title = "Ważność cech - XGBoost")
vip_xgb
```

Oba modele pokazują, że dystans jest najważniejszy, a jego efekt rośnie wraz z ruchem na drodze i maleje dla pojazdów silnikowych. Czas przygotowania zamówienia jest stabilnym czynnikiem. Logistycznie największy zysk da skracanie trasy i unikanie korków. Boosting potwierdza, że najdłuższe czasy generują długie trasy w korkach i bez pojazdu silnikowego. Pogoda ma mniejszy wpływ globalny, może być to spowodowane rzadszymi kategoriami. Cechy `prep_per_km` i `is_motorized` realnie mają znaczenie. 

### Wybór modelu i zapis

Końcowo model **Elastic Net** daje najniższy błąd i największa stabilność, a klucz do dokładnych prognoz to dystans + ruch na drodze + typ pojazdu. Dodatkową uwagę należy zwrócić na ekstremalne warunki pogodowe (śnieg) oraz ograniczenia w postaci małej ilości danych w skrajnościach (noc i wcześniej wymieniony śnieg). Można rozważyć dodatkowe cechy czasowe jak dzień tygodnia oraz dodanie do modelu XGB dla najtrudniejszych tras.

```{r}
#| eval: true

best_row <- wyniki_test |> arrange(rmse, mae) |> slice(1)
best_row

if (best_row$model == "Random Forest") {
  saveRDS(list(workflow = final_rf, fit = fit_rf), file = "model_best_rf.rds")
} else if (best_row$model == "XGBoost") {
  saveRDS(list(workflow = final_xgb, fit = fit_xgb), file = "model_best_xgb.rds")
} else if (best_row$model == "Elastic Net") {
  saveRDS(list(workflow = final_enet, fit = fit_enet), file = "model_best_enet.rds")
} else {
  saveRDS(list(workflow = wf_lm, fit = fit_lm), file = "model_best_lm.rds")
}
```